{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Ticket Assignment - Capstone Project - Approach2\n",
    "\n",
    "## Problem Statement - \n",
    "\n",
    "In most of the IT organizations, the assignment of incidents to appropriate IT groups is still a manual process. Manual assignment of incidents is time consuming and requires human efforts. There may be mistakes due to human errors and resource consumption is carried out ineffectively because of the misaddressing. On the other hand, manual assignment increases the response and resolution times which result in user satisfaction deterioration / poor customer service. \n",
    "\n",
    "_<font color=blue>This capstone project intends to reduce the manual intervention of IT operations or Service desk teams by automating the ticket assignment process.The goal here is to create a text classification based ML model that can automatically  classify any new tickets by analysing ticket description to one of the relevant Assignment groups, which could be later integrated to any ITSM tool like Service Now. Based on the ticket description our model will output the probability of assigning it to one of the 74 Groups.</font>_\n",
    "\n",
    "The solution would be implemented using below approach:\n",
    "\n",
    "In the AS-IS process it's mentioned that around ~54% of the incidents are resolved by L1 / L2 teams and the rest will be resolved as L3. So the assumption is that GRP_0 and GRP_8 which contribute 54% of the tickets are related to L1/L2 teams and the rest of the tickets belongs to L3 teams\n",
    "\n",
    "So firstly, the ticket would be classified into L1/L2 or L3 classes and then it would be further classified into one of the given assignment groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assignment_group</th>\n",
       "      <th>Target</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>num_wds</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>uniq_wds</th>\n",
       "      <th>token_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRP_0</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>login issue verified user detailsemployee mana...</td>\n",
       "      <td>20</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>17</td>\n",
       "      <td>login issue verified user detailsemployee mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRP_0</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>outlook hmjdrvpbkomuaywn teammy meetingsskype ...</td>\n",
       "      <td>12</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>11</td>\n",
       "      <td>outlook hmjdrvpbkomuaywn teammy meetingsskype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRP_0</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>cant log vpn eylqgodmybqkwiami cannot log vpn</td>\n",
       "      <td>7</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>5</td>\n",
       "      <td>cant log vpn eylqgodmybqkwiami cannot log vpn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRP_0</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>unable access hrtool page unable access hrtool...</td>\n",
       "      <td>8</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>unable access hrtool page unable access hrtool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRP_0</td>\n",
       "      <td>L1/L2</td>\n",
       "      <td>skype error skype error</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>skype error skype error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Assignment_group Target                                cleaned_description  \\\n",
       "0            GRP_0  L1/L2  login issue verified user detailsemployee mana...   \n",
       "1            GRP_0  L1/L2  outlook hmjdrvpbkomuaywn teammy meetingsskype ...   \n",
       "2            GRP_0  L1/L2      cant log vpn eylqgodmybqkwiami cannot log vpn   \n",
       "3            GRP_0  L1/L2  unable access hrtool page unable access hrtool...   \n",
       "4            GRP_0  L1/L2                            skype error skype error   \n",
       "\n",
       "   num_wds  avg_word  uniq_wds  \\\n",
       "0       20  6.900000        17   \n",
       "1       12  8.083333        11   \n",
       "2        7  5.571429         5   \n",
       "3        8  5.500000         4   \n",
       "4        4  5.000000         2   \n",
       "\n",
       "                                          token_desc  \n",
       "0  login issue verified user detailsemployee mana...  \n",
       "1  outlook hmjdrvpbkomuaywn teammy meetingsskype ...  \n",
       "2      cant log vpn eylqgodmybqkwiami cannot log vpn  \n",
       "3  unable access hrtool page unable access hrtool...  \n",
       "4                            skype error skype error  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents_level = pd.read_csv('dataset/processed_file_modellling.csv',encoding='utf-8')\n",
    "df_incidents_level.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is very imbalanced, we will be considering a subset of groups for predictions. In 74 groups, 46% of tickets belong to group 1 and 16 groups have more than 100 tickets and around 22 groups have more than 50 tickets, rest of the Assignment groups have very less ticket counts which might not add much value to the model prediction. If we conducted random sampling towards all the subcategories, then we would face a problem that we might miss all the tickets in some categories. Hence, we considered the groups that have more than 50 tickets in this appoach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents_level = df_incidents_level[df_incidents_level['Assignment_group'].map(df_incidents_level['Assignment_group'].value_counts()) > 50]\n",
    "x = df_incidents_level['token_desc']\n",
    "y = df_incidents_level['Target']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "# encoding train labels \n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=13,stratify=y)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights\n",
    "\n",
    "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(y_train):\n",
    "    w_array[i] = class_weights[val]\n",
    "    \n",
    "    \n",
    "log_cols=[\"Classifier\", \"accuracy\",\"f1_score\"]\n",
    "log1 = pd.DataFrame(columns=log_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Pass the data to various models which learns to classify the tickets into one of the two groups -  L1/L2 or L3 class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8033635187580854\n",
      "f1 score 0.8121445771605216\n",
      "logloss: 0.434 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       923\n",
      "           1       0.87      0.60      0.71       623\n",
      "\n",
      "    accuracy                           0.80      1546\n",
      "   macro avg       0.82      0.77      0.78      1546\n",
      "weighted avg       0.82      0.80      0.79      1546\n",
      "\n",
      "[[868  55]\n",
      " [249 374]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "predictions = nb.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test)) \n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "\n",
    "log_entry = pd.DataFrame([[\"MultinomialNB\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log1 = log1.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8195342820181113\n",
      "f1 score 0.8184339374503905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84       923\n",
      "           1       0.75      0.82      0.79       623\n",
      "\n",
      "    accuracy                           0.82      1546\n",
      "   macro avg       0.81      0.82      0.82      1546\n",
      "weighted avg       0.82      0.82      0.82      1546\n",
      "\n",
      "[[754 169]\n",
      " [110 513]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(loss='hinge',random_state=42,class_weight='balanced'))),\n",
    "               ])\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "log_entry = pd.DataFrame([[\"LinearSVC\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log1 = log1.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7613195342820182\n",
      "f1 score 0.7598260227617155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77       923\n",
      "           1       0.65      0.89      0.75       623\n",
      "\n",
      "    accuracy                           0.76      1546\n",
      "   macro avg       0.78      0.78      0.76      1546\n",
      "weighted avg       0.80      0.76      0.76      1546\n",
      "\n",
      "[[620 303]\n",
      " [ 66 557]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None,class_weight='balanced')),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"SGDClassifier\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log1 = log1.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7826649417852523\n",
      "f1 score 0.7820902259321157\n",
      "logloss: 2.714 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       923\n",
      "           1       0.72      0.75      0.74       623\n",
      "\n",
      "    accuracy                           0.78      1546\n",
      "   macro avg       0.77      0.78      0.78      1546\n",
      "weighted avg       0.78      0.78      0.78      1546\n",
      "\n",
      "[[744 179]\n",
      " [157 466]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_1 = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5,class_weight='balanced')),\n",
    "               ])\n",
    "logreg_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg_1.predict(X_test)\n",
    "predictions = logreg_1.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"LogisticRegression\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log1 = log1.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.761320</td>\n",
       "      <td>0.759826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.782665</td>\n",
       "      <td>0.782090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.803364</td>\n",
       "      <td>0.812145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.819534</td>\n",
       "      <td>0.818434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  f1_score\n",
       "Classifier                            \n",
       "SGDClassifier       0.761320  0.759826\n",
       "LogisticRegression  0.782665  0.782090\n",
       "MultinomialNB       0.803364  0.812145\n",
       "LinearSVC           0.819534  0.818434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log1.set_index([\"Classifier\"],inplace=True)\n",
    "log1.sort_values(by=['f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x222322bc4e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log1.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC gives better performance compared to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1_l2_classification.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(svc, 'l1_l2_classification.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1/L2': 0, 'L3': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L3'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "model = joblib.load('l1_l2_classification.pkl')\n",
    "\n",
    "sentence = 'job failed in scheduler'\n",
    "encoder.inverse_transform(model.predict([sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model1 - Classification of L1/L2 tickets between GRP0 and GRP8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4614, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents_l1_l2 = df_incidents_level[df_incidents_level['Target'] == 'L1/L2']\n",
    "df_incidents_l1_l2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRP_0    3971\n",
       "GRP_8     643\n",
       "Name: Assignment_group, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents_l1_l2.Assignment_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_incidents_l1_l2['token_desc']\n",
    "y = df_incidents_l1_l2['Assignment_group']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "# encoding train labels \n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=13,stratify=y)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights\n",
    "\n",
    "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(y_train):\n",
    "    w_array[i] = class_weights[val]\n",
    "    \n",
    "    \n",
    "log_cols=[\"Classifier\", \"accuracy\",\"f1_score\"]\n",
    "log2 = pd.DataFrame(columns=log_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9924160346695557\n",
      "f1 score 0.9925051452439715\n",
      "logloss: 0.032 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       794\n",
      "           1       1.00      0.95      0.97       129\n",
      "\n",
      "    accuracy                           0.99       923\n",
      "   macro avg       1.00      0.97      0.98       923\n",
      "weighted avg       0.99      0.99      0.99       923\n",
      "\n",
      "[[794   0]\n",
      " [  7 122]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "predictions = nb.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test)) \n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "\n",
    "log_entry = pd.DataFrame([[\"MultinomialNB\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log2 = log2.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.9967497291440953\n",
      "Test f1 score 0.9967657840184381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       794\n",
      "           1       1.00      0.98      0.99       129\n",
      "\n",
      "    accuracy                           1.00       923\n",
      "   macro avg       1.00      0.99      0.99       923\n",
      "weighted avg       1.00      1.00      1.00       923\n",
      "\n",
      "[[794   0]\n",
      " [  3 126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "svc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(loss='hinge',random_state=42,class_weight='balanced'))),\n",
    "               ])\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('Test f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"LinearSVC\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log2 = log2.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9945828819068255\n",
      "f1 score 0.9945917164787735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       794\n",
      "           1       0.98      0.98      0.98       129\n",
      "\n",
      "    accuracy                           0.99       923\n",
      "   macro avg       0.99      0.99      0.99       923\n",
      "weighted avg       0.99      0.99      0.99       923\n",
      "\n",
      "[[792   2]\n",
      " [  3 126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None,class_weight='balanced')),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "\n",
    "log_entry = pd.DataFrame([[\"SGDClassifier\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log2 = log2.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9967497291440953\n",
      "f1 score 0.9967657840184381\n",
      "logloss: 0.035 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       794\n",
      "           1       1.00      0.98      0.99       129\n",
      "\n",
      "    accuracy                           1.00       923\n",
      "   macro avg       1.00      0.99      0.99       923\n",
      "weighted avg       1.00      1.00      1.00       923\n",
      "\n",
      "[[794   0]\n",
      " [  3 126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_1 = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5,class_weight='balanced')),\n",
    "               ])\n",
    "logreg_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg_1.predict(X_test)\n",
    "predictions = logreg_1.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"LogisticRegression\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log2 = log2.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.992416</td>\n",
       "      <td>0.992505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.994583</td>\n",
       "      <td>0.994592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.996750</td>\n",
       "      <td>0.996766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.996750</td>\n",
       "      <td>0.996766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  f1_score\n",
       "Classifier                            \n",
       "MultinomialNB       0.992416  0.992505\n",
       "SGDClassifier       0.994583  0.994592\n",
       "LinearSVC           0.996750  0.996766\n",
       "LogisticRegression  0.996750  0.996766"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2.set_index([\"Classifier\"],inplace=True)\n",
    "log2.sort_values(by=['f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22231852518>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log2.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_l1_l2.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Save the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(logreg_1, 'model_l1_l2.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GRP_0': 0, 'GRP_8': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GRP_8'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.externals import joblib\n",
    "model = joblib.load('model_l1_l2.pkl')\n",
    "\n",
    "sentence = 'job failed in scheduler'\n",
    "encoder.inverse_transform(model.predict([sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to classify L3 tickets\n",
    "\n",
    "Lets's now train the models to classify the L3 tickets into one of the assignement groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incidents_l3 = df_incidents_level[df_incidents_level['Target'] == 'L3']\n",
    "df_incidents_l3 = df_incidents_l3[df_incidents_l3['Assignment_group'].map(df_incidents_l3['Assignment_group'].value_counts()) > 50]\n",
    "x = df_incidents_l3['token_desc']\n",
    "y = df_incidents_l3['Assignment_group']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "# encoding train labels \n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=13,stratify=y)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights\n",
    "\n",
    "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(y_train):\n",
    "    w_array[i] = class_weights[val]\n",
    "    \n",
    "log_cols=[\"Classifier\", \"accuracy\",\"f1_score\"]\n",
    "log = pd.DataFrame(columns=log_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5120385232744783\n",
      "f1 score 0.5720780575411325\n",
      "logloss: 1.841 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.62      0.75        29\n",
      "           1       0.49      0.82      0.61        50\n",
      "           2       0.52      0.59      0.55        29\n",
      "           3       1.00      0.17      0.30        23\n",
      "           4       0.00      0.00      0.00        17\n",
      "           5       0.94      1.00      0.97        16\n",
      "           6       1.00      0.06      0.11        17\n",
      "           7       0.44      0.61      0.51        44\n",
      "           8       0.33      0.94      0.48        49\n",
      "           9       0.61      0.88      0.72        58\n",
      "          10       0.86      0.26      0.40        23\n",
      "          11       0.00      0.00      0.00        11\n",
      "          12       0.00      0.00      0.00        19\n",
      "          13       0.46      0.42      0.44        40\n",
      "          14       0.00      0.00      0.00        12\n",
      "          15       1.00      0.05      0.09        21\n",
      "          16       0.00      0.00      0.00        12\n",
      "          17       1.00      0.20      0.33        20\n",
      "          18       1.00      0.26      0.41        31\n",
      "          19       0.52      0.41      0.45        37\n",
      "          20       1.00      0.14      0.25        14\n",
      "          21       0.50      0.88      0.64        51\n",
      "\n",
      "    accuracy                           0.51       623\n",
      "   macro avg       0.57      0.38      0.36       623\n",
      "weighted avg       0.58      0.51      0.45       623\n",
      "\n",
      "[[18  0  3  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0 41  0  0  0  1  0  2  2  4  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 17  0  0  0  0  2  5  1  0  0  0  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  7  0  4  0  0  0  1  7  1  0  0  0  2  0  0  0  0  0  0  0  1]\n",
      " [ 0  3  0  0  0  0  0  1 12  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  1  0  4  1  0  0  0  1  0  0  0  0  0  7  0  0]\n",
      " [ 0  4  0  0  0  0  0 27  5  4  0  0  0  4  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3 46  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  1 51  1  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  1  0  0  0  0  1  6  3  6  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  1  0  0  0  0  0  1  9  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  5  0  0]\n",
      " [ 0  3  0  0  0  0  0 10  6  4  0  0  0 17  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  5  2  2  0  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  2  3 10  0  0  0  2  0  1  0  0  0  0  0  0]\n",
      " [ 0  7  1  0  0  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  7  0  0  0  0  0  2  5  0  0  0  0  2  0  0  0  4  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  8  0  0 20]\n",
      " [ 0  0  2  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 15  0 19]\n",
      " [ 0  0  0  0  0  0  0  4  5  1  0  0  0  2  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  1  0  0  0  0  0  4  0  0  0  0  1  0  0  0  0  0  0  0 45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "predictions = nb.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test)) \n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"MultinomialNB\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.709470304975923\n",
      "Test f1 score 0.7120737930288871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87        29\n",
      "           1       0.67      0.78      0.72        50\n",
      "           2       0.59      0.66      0.62        29\n",
      "           3       0.57      0.57      0.57        23\n",
      "           4       0.76      0.76      0.76        17\n",
      "           5       1.00      1.00      1.00        16\n",
      "           6       0.65      0.65      0.65        17\n",
      "           7       0.52      0.66      0.58        44\n",
      "           8       0.71      0.84      0.77        49\n",
      "           9       0.84      0.83      0.83        58\n",
      "          10       0.82      0.61      0.70        23\n",
      "          11       0.50      0.45      0.48        11\n",
      "          12       0.76      0.84      0.80        19\n",
      "          13       0.53      0.47      0.50        40\n",
      "          14       0.46      0.50      0.48        12\n",
      "          15       0.60      0.43      0.50        21\n",
      "          16       0.75      0.25      0.38        12\n",
      "          17       0.73      0.55      0.63        20\n",
      "          18       0.85      0.74      0.79        31\n",
      "          19       0.72      0.84      0.77        37\n",
      "          20       0.71      0.71      0.71        14\n",
      "          21       0.88      0.82      0.85        51\n",
      "\n",
      "    accuracy                           0.71       623\n",
      "   macro avg       0.71      0.67      0.68       623\n",
      "weighted avg       0.72      0.71      0.71       623\n",
      "\n",
      "[[24  0  2  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 39  0  2  1  0  0  0  1  2  1  0  0  1  0  2  0  0  0  0  1  0]\n",
      " [ 1  0 19  0  0  0  4  0  0  0  0  1  1  1  0  0  0  0  0  1  0  1]\n",
      " [ 0  2  0 13  0  0  0  2  2  0  0  0  2  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  2  1 13  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 11  0  1  0  0  0  1  1  0  0  0  0  0  2  0  0]\n",
      " [ 0  1  0  0  0  0  0 29  1  1  0  1  0  6  2  1  0  2  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  0  3 41  0  0  0  0  0  1  0  0  1  0  0  1  0]\n",
      " [ 0  1  0  1  0  0  0  1  0 48  2  0  0  2  1  1  0  1  0  0  0  0]\n",
      " [ 0  2  3  1  1  0  1  0  1  0 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0  0  1  1  0  0  5  0  0  0  0  1  0  0  1  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  2  0  1  0  0  0  9  3  2  0  1  0 19  1  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  4  1  0  0  0  0  0  6  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  1  1  4  0  0  0  1  1  9  0  0  0  0  2  0]\n",
      " [ 0  5  0  0  0  0  0  0  2  0  0  0  0  0  1  0  3  0  0  1  0  0]\n",
      " [ 0  2  1  2  0  0  0  2  0  0  0  0  0  2  0  0  0 11  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 23  3  0  3]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  2 31  0  2]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  1  0  1  0  0  0  0  0  0 10  0]\n",
      " [ 0  0  1  1  0  0  0  1  1  0  0  0  0  1  0  0  0  0  2  2  0 42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "svc = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(loss='hinge',random_state=42,class_weight='balanced'))),\n",
    "               ])\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('Test f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"LinearSVC\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6548956661316212\n",
      "f1 score 0.6552730359075201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.79        29\n",
      "           1       0.72      0.52      0.60        50\n",
      "           2       0.65      0.69      0.67        29\n",
      "           3       0.50      0.52      0.51        23\n",
      "           4       0.56      0.82      0.67        17\n",
      "           5       0.76      1.00      0.86        16\n",
      "           6       0.59      0.76      0.67        17\n",
      "           7       0.74      0.45      0.56        44\n",
      "           8       0.73      0.65      0.69        49\n",
      "           9       0.78      0.74      0.76        58\n",
      "          10       0.70      0.70      0.70        23\n",
      "          11       0.31      0.73      0.43        11\n",
      "          12       0.68      0.89      0.77        19\n",
      "          13       0.62      0.33      0.43        40\n",
      "          14       0.38      0.50      0.43        12\n",
      "          15       0.48      0.52      0.50        21\n",
      "          16       0.33      0.50      0.40        12\n",
      "          17       0.50      0.60      0.55        20\n",
      "          18       0.72      0.74      0.73        31\n",
      "          19       0.77      0.65      0.71        37\n",
      "          20       0.52      0.86      0.65        14\n",
      "          21       0.86      0.82      0.84        51\n",
      "\n",
      "    accuracy                           0.65       623\n",
      "   macro avg       0.62      0.67      0.63       623\n",
      "weighted avg       0.68      0.65      0.65       623\n",
      "\n",
      "[[22  0  3  0  0  1  0  0  0  0  0  2  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 26  0  5  2  1  0  0  1  2  1  1  1  1  0  2  5  2  0  0  0  0]\n",
      " [ 2  0 20  0  1  0  4  0  0  0  0  1  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 1  2  0 12  0  0  1  0  1  0  0  1  3  0  0  0  0  0  1  0  1  0]\n",
      " [ 0  0  1  1 14  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 13  0  0  0  0  1  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  2  1  1  1 20  2  4  0  2  0  2  1  3  1  4  0  0  0  0]\n",
      " [ 0  1  0  0  2  2  0  3 32  1  1  3  0  0  1  0  1  1  0  0  1  0]\n",
      " [ 0  1  0  0  0  0  0  0  0 43  4  0  0  3  2  4  0  1  0  0  0  0]\n",
      " [ 0  1  2  0  2  0  0  0  1  0 16  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  8  0  0  0  0  1  0  0  0  1  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  2  0  0  1  0  1  2  3  2  1  3  1 13  4  1  1  2  0  0  3  0]\n",
      " [ 1  0  0  0  1  0  0  1  1  0  0  0  0  0  6  1  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  3  0  1  0  1  0 11  1  1  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  1  2  0  6  0  0  2  0  0]\n",
      " [ 0  2  0  2  0  0  0  0  1  0  0  0  0  0  0  1  0 12  0  0  2  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 23  1  0  4]\n",
      " [ 0  0  1  0  0  0  2  0  0  0  0  0  2  0  0  0  0  0  5 24  0  3]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0  0  0 12  0]\n",
      " [ 0  0  2  1  1  0  0  0  0  0  0  1  0  0  0  0  0  0  3  1  0 42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=100, tol=None,class_weight='balanced')),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"SGDClassifier\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6902086677367576\n",
      "f1 score 0.6920296264657881\n",
      "logloss: 2.188 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        29\n",
      "           1       0.60      0.70      0.65        50\n",
      "           2       0.53      0.62      0.57        29\n",
      "           3       0.67      0.52      0.59        23\n",
      "           4       0.88      0.82      0.85        17\n",
      "           5       1.00      1.00      1.00        16\n",
      "           6       0.73      0.65      0.69        17\n",
      "           7       0.50      0.55      0.52        44\n",
      "           8       0.66      0.84      0.74        49\n",
      "           9       0.82      0.79      0.81        58\n",
      "          10       0.76      0.57      0.65        23\n",
      "          11       0.67      0.55      0.60        11\n",
      "          12       0.76      0.84      0.80        19\n",
      "          13       0.45      0.50      0.48        40\n",
      "          14       0.44      0.58      0.50        12\n",
      "          15       0.73      0.38      0.50        21\n",
      "          16       0.50      0.17      0.25        12\n",
      "          17       0.57      0.60      0.59        20\n",
      "          18       0.80      0.77      0.79        31\n",
      "          19       0.70      0.84      0.77        37\n",
      "          20       0.69      0.64      0.67        14\n",
      "          21       0.93      0.78      0.85        51\n",
      "\n",
      "    accuracy                           0.69       623\n",
      "   macro avg       0.70      0.66      0.67       623\n",
      "weighted avg       0.70      0.69      0.69       623\n",
      "\n",
      "[[25  0  2  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  0  2  0  0  0  0  1  2  1  0  0  4  1  1  1  2  0  0  0  0]\n",
      " [ 2  0 18  0  0  0  2  0  1  0  0  1  1  0  0  0  0  0  0  2  1  1]\n",
      " [ 0  2  1 12  0  0  0  1  2  1  0  0  2  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  1  0 14  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 11  0  1  0  0  0  1  1  0  0  0  0  0  2  0  0]\n",
      " [ 0  2  0  0  0  0  1 24  1  1  1  1  0  8  2  1  0  2  0  0  0  0]\n",
      " [ 0  2  0  0  1  0  0  2 41  0  0  0  0  0  2  0  0  0  0  0  1  0]\n",
      " [ 0  2  0  1  0  0  0  3  0 46  2  0  0  1  1  1  0  1  0  0  0  0]\n",
      " [ 0  1  3  1  0  0  0  0  3  0 13  0  0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0  0  0  2  0  0  6  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  2  0  0  0  0  0 10  2  2  0  1  0 20  1  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  2  2  0  0  0  0  0  7  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  1  4  0  0  0  3  1  8  0  0  0  0  2  0]\n",
      " [ 0  6  0  0  0  0  0  1  1  0  0  0  0  0  1  0  2  0  0  1  0  0]\n",
      " [ 0  2  1  0  0  0  0  2  1  0  0  0  0  2  0  0  0 12  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 24  3  0  2]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  3 31  0  0]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  2  0  0  0  1  0  0  9  0]\n",
      " [ 0  0  2  1  0  0  0  1  1  0  0  0  0  0  0  0  0  0  3  3  0 40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_1 = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5,class_weight='balanced')),\n",
    "               ])\n",
    "logreg_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg_1.predict(X_test)\n",
    "predictions = logreg_1.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"LogisticRegression\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols)\n",
    "log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.512039</td>\n",
       "      <td>0.572078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.654896</td>\n",
       "      <td>0.655273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.690209</td>\n",
       "      <td>0.692030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.709470</td>\n",
       "      <td>0.712074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy  f1_score\n",
       "Classifier                            \n",
       "MultinomialNB       0.512039  0.572078\n",
       "SGDClassifier       0.654896  0.655273\n",
       "LogisticRegression  0.690209  0.692030\n",
       "LinearSVC           0.709470  0.712074"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.set_index([\"Classifier\"],inplace=True)\n",
    "log.sort_values(by=['f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2223294b5c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tune GridSearchCV \n",
    "\n",
    "Let's tune each of the models using GridsearchCV to identify the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.6749712122841616\n",
      "Best Params:  {'clf__estimator__C': 1, 'clf__estimator__loss': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"clf__estimator__C\": [0.1, 1, 10, 100, 1000],  \n",
    "              'clf__estimator__loss': ['hinge','squared_hinge'],}  \n",
    "  \n",
    "clf_svc = GridSearchCV(svc, param_grid=params, refit = True, verbose = 1,scoring='f1_weighted') \n",
    "# fitting the model for grid search \n",
    "clf_svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", clf_svc.best_score_)\n",
    "print(\"Best Params: \", clf_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7046548956661316\n",
      "f1 score 0.7067989174530586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87        29\n",
      "           1       0.65      0.72      0.69        50\n",
      "           2       0.58      0.66      0.61        29\n",
      "           3       0.55      0.52      0.53        23\n",
      "           4       0.76      0.76      0.76        17\n",
      "           5       1.00      1.00      1.00        16\n",
      "           6       0.60      0.71      0.65        17\n",
      "           7       0.56      0.66      0.60        44\n",
      "           8       0.69      0.84      0.76        49\n",
      "           9       0.84      0.81      0.82        58\n",
      "          10       0.81      0.57      0.67        23\n",
      "          11       0.50      0.45      0.48        11\n",
      "          12       0.73      0.84      0.78        19\n",
      "          13       0.60      0.53      0.56        40\n",
      "          14       0.40      0.50      0.44        12\n",
      "          15       0.56      0.43      0.49        21\n",
      "          16       0.50      0.25      0.33        12\n",
      "          17       0.69      0.55      0.61        20\n",
      "          18       0.85      0.74      0.79        31\n",
      "          19       0.74      0.84      0.78        37\n",
      "          20       0.69      0.64      0.67        14\n",
      "          21       0.88      0.84      0.86        51\n",
      "\n",
      "    accuracy                           0.70       623\n",
      "   macro avg       0.69      0.67      0.67       623\n",
      "weighted avg       0.71      0.70      0.70       623\n",
      "\n",
      "[[24  0  2  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 36  0  3  1  0  0  0  1  2  1  0  0  1  0  2  1  1  0  0  1  0]\n",
      " [ 1  0 19  0  0  0  4  0  0  0  0  1  1  1  0  0  0  0  0  1  0  1]\n",
      " [ 0  2  1 12  0  0  0  2  2  0  0  0  2  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  2  1 13  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 12  0  0  0  0  1  1  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  1 29  1  1  0  1  0  5  2  1  0  2  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  0  2 41  0  0  0  0  0  2  0  0  1  0  0  1  0]\n",
      " [ 0  1  0  1  0  0  0  2  0 47  2  0  0  1  2  1  0  1  0  0  0  0]\n",
      " [ 0  2  3  1  1  0  1  0  2  0 13  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0  0  1  1  0  0  5  0  0  0  0  1  0  0  1  0  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  2  0  0  0  0  0  6  3  2  0  1  1 21  1  2  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  3  1  0  0  0  0  0  6  1  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  1  1  4  0  0  0  1  1  9  0  0  0  0  2  0]\n",
      " [ 0  5  0  0  0  0  0  0  2  0  0  0  0  0  1  0  3  0  0  1  0  0]\n",
      " [ 0  2  1  2  0  0  0  2  0  0  0  0  0  2  0  0  0 11  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 23  3  0  3]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  2 31  0  2]\n",
      " [ 0  0  0  0  0  0  1  2  1  0  0  0  0  1  0  0  0  0  0  0  9  0]\n",
      " [ 0  0  1  1  0  0  0  1  1  0  0  0  0  0  0  0  0  0  2  2  0 43]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_svc.best_estimator_.predict(X_test)\n",
    "#predictions = clf_svc.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "#print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"LinearSVC_best_estimator\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols,index=['LinearSVC_best_estimator'])\n",
    "log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.6731476997187076\n",
      "Best Params:  {'clf__alpha': 0.001, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "    \"clf__loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"clf__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"clf__penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "}\n",
    "\n",
    "clf_sgd = GridSearchCV(sgd, param_grid=params,refit = True, verbose = 1,scoring='f1_weighted')\n",
    "clf_sgd.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", clf_sgd.best_score_)\n",
    "print(\"Best Params: \", clf_sgd.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6886035313001605\n",
      "f1 score 0.6883759728396966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89        29\n",
      "           1       0.73      0.60      0.66        50\n",
      "           2       0.59      0.69      0.63        29\n",
      "           3       0.48      0.52      0.50        23\n",
      "           4       0.74      0.82      0.78        17\n",
      "           5       0.80      1.00      0.89        16\n",
      "           6       0.59      0.76      0.67        17\n",
      "           7       0.62      0.57      0.60        44\n",
      "           8       0.75      0.80      0.77        49\n",
      "           9       0.79      0.76      0.77        58\n",
      "          10       0.82      0.61      0.70        23\n",
      "          11       0.44      0.73      0.55        11\n",
      "          12       0.70      0.84      0.76        19\n",
      "          13       0.64      0.45      0.53        40\n",
      "          14       0.40      0.50      0.44        12\n",
      "          15       0.50      0.48      0.49        21\n",
      "          16       0.40      0.50      0.44        12\n",
      "          17       0.57      0.60      0.59        20\n",
      "          18       0.79      0.74      0.77        31\n",
      "          19       0.68      0.70      0.69        37\n",
      "          20       0.67      0.71      0.69        14\n",
      "          21       0.88      0.82      0.85        51\n",
      "\n",
      "    accuracy                           0.69       623\n",
      "   macro avg       0.66      0.69      0.67       623\n",
      "weighted avg       0.70      0.69      0.69       623\n",
      "\n",
      "[[25  0  3  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 30  0  4  1  1  0  0  1  2  1  0  1  1  0  2  4  2  0  0  0  0]\n",
      " [ 2  0 20  0  0  0  3  0  0  0  0  1  1  0  0  0  0  0  0  1  1  0]\n",
      " [ 0  2  0 12  0  0  1  2  1  0  0  1  2  0  0  0  0  1  0  1  0  0]\n",
      " [ 0  0  1  1 14  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 13  0  0  0  0  1  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  1  1  1 25  2  3  0  1  0  3  1  2  1  3  0  0  0  0]\n",
      " [ 0  1  0  0  1  2  0  2 39  0  0  1  0  0  2  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  1  0  0  0  1  0 44  2  0  0  3  2  3  0  1  0  0  0  0]\n",
      " [ 0  1  3  2  1  0  1  0  0  0 14  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  8  0  0  0  0  1  0  0  1  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  4  3  3  0  3  1 18  2  2  1  0  0  0  2  0]\n",
      " [ 0  0  0  0  1  0  0  3  1  0  0  0  0  0  6  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  1  1  4  0  0  0  0  1 10  1  0  0  0  2  0]\n",
      " [ 0  1  0  1  0  0  0  0  1  0  0  0  0  0  1  0  6  0  0  2  0  0]\n",
      " [ 0  2  1  2  0  0  0  1  0  0  0  0  0  2  0  0  0 12  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 23  3  0  3]\n",
      " [ 0  0  1  0  0  0  2  0  0  0  0  0  1  0  0  0  0  0  4 26  0  3]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  0  1  0  1  0  0  0  0  0  0 10  0]\n",
      " [ 0  0  2  1  0  0  0  0  2  0  0  0  0  0  0  0  0  0  2  2  0 42]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_sgd.best_estimator_.predict(X_test)\n",
    "#predictions = clf_svc.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "#print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"SGD_best_estimator\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols,index=['SGD_best_estimator'])\n",
    "log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.671752309610414\n",
      "Best Params:  {'clf__C': 100.0, 'clf__max_iter': 4000, 'clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "  'clf__penalty': ['l2'],\n",
    "  'clf__C': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0,1e2,1e4,1e5],\n",
    "  'clf__max_iter': [100,4000,5000],\n",
    "}\n",
    "\n",
    "clf_lr = GridSearchCV(logreg_1, param_grid=params,refit = True,verbose = 1,scoring='f1_weighted')\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score: \", clf_lr.best_score_)\n",
    "print(\"Best Params: \", clf_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7062600321027287\n",
      "f1 score 0.7053918749872033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93        29\n",
      "           1       0.66      0.66      0.66        50\n",
      "           2       0.58      0.66      0.61        29\n",
      "           3       0.62      0.57      0.59        23\n",
      "           4       0.82      0.82      0.82        17\n",
      "           5       1.00      1.00      1.00        16\n",
      "           6       0.63      0.71      0.67        17\n",
      "           7       0.55      0.61      0.58        44\n",
      "           8       0.74      0.86      0.79        49\n",
      "           9       0.84      0.79      0.81        58\n",
      "          10       0.81      0.57      0.67        23\n",
      "          11       0.55      0.55      0.55        11\n",
      "          12       0.76      0.84      0.80        19\n",
      "          13       0.52      0.55      0.54        40\n",
      "          14       0.35      0.50      0.41        12\n",
      "          15       0.56      0.43      0.49        21\n",
      "          16       0.36      0.33      0.35        12\n",
      "          17       0.69      0.55      0.61        20\n",
      "          18       0.79      0.74      0.77        31\n",
      "          19       0.76      0.84      0.79        37\n",
      "          20       0.71      0.71      0.71        14\n",
      "          21       0.91      0.80      0.85        51\n",
      "\n",
      "    accuracy                           0.71       623\n",
      "   macro avg       0.69      0.68      0.68       623\n",
      "weighted avg       0.71      0.71      0.71       623\n",
      "\n",
      "[[26  0  2  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 33  0  2  0  0  0  0  1  2  1  0  0  2  1  2  4  2  0  0  0  0]\n",
      " [ 1  0 19  0  0  0  3  0  0  0  0  1  1  1  0  0  0  0  0  1  1  1]\n",
      " [ 0  2  1 13  0  0  0  2  1  0  0  0  2  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  1  0 14  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0 12  0  0  0  0  1  1  1  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  1 27  1  1  0  1  0  7  2  1  0  2  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  0  2 42  0  0  0  0  0  2  0  0  0  0  0  1  0]\n",
      " [ 0  1  0  1  0  0  0  2  0 46  2  0  0  1  2  2  0  1  0  0  0  0]\n",
      " [ 0  1  3  1  1  0  1  0  2  0 13  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  0  0  0  2  0  0  6  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0 16  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  2  0  0  0  0  0  8  2  2  0  1  0 22  1  1  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  2  2  0  0  0  0  0  6  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  1  0  4  0  0  0  1  2  9  1  0  0  0  2  0]\n",
      " [ 0  4  0  0  0  0  0  0  2  0  0  0  0  0  1  0  4  0  0  1  0  0]\n",
      " [ 0  2  1  2  0  0  0  2  0  0  0  0  0  2  0  0  0 11  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 23  3  0  3]\n",
      " [ 0  0  1  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  3 31  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  1  0  0  0  0  2  0  0  0  0  0  0 10  0]\n",
      " [ 0  0  1  1  0  0  0  1  1  0  0  0  0  1  0  0  0  0  3  2  0 41]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_lr.best_estimator_.predict(X_test)\n",
    "#predictions = clf_svc.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print('f1 score %s' % f1_score(y_pred, y_test,average='weighted')) \n",
    "#print (\"logloss: %0.3f \" % multiclass_logloss(y_test,predictions))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "log_entry = pd.DataFrame([[\"LogisticRegression_best_estimator\",accuracy_score(y_pred, y_test),f1_score(y_pred, y_test,average='weighted')]], columns=log_cols,index=['LogisticRegression_best_estimator'])\n",
    "log = log.append(log_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512039</td>\n",
       "      <td>0.572078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654896</td>\n",
       "      <td>0.655273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_best_estimator</th>\n",
       "      <td>SGD_best_estimator</td>\n",
       "      <td>0.688604</td>\n",
       "      <td>0.688376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690209</td>\n",
       "      <td>0.692030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_best_estimator</th>\n",
       "      <td>LogisticRegression_best_estimator</td>\n",
       "      <td>0.706260</td>\n",
       "      <td>0.705392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC_best_estimator</th>\n",
       "      <td>LinearSVC_best_estimator</td>\n",
       "      <td>0.704655</td>\n",
       "      <td>0.706799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709470</td>\n",
       "      <td>0.712074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Classifier  \\\n",
       "MultinomialNB                                                    NaN   \n",
       "SGDClassifier                                                    NaN   \n",
       "SGD_best_estimator                                SGD_best_estimator   \n",
       "LogisticRegression                                               NaN   \n",
       "LogisticRegression_best_estimator  LogisticRegression_best_estimator   \n",
       "LinearSVC_best_estimator                    LinearSVC_best_estimator   \n",
       "LinearSVC                                                        NaN   \n",
       "\n",
       "                                   accuracy  f1_score  \n",
       "MultinomialNB                      0.512039  0.572078  \n",
       "SGDClassifier                      0.654896  0.655273  \n",
       "SGD_best_estimator                 0.688604  0.688376  \n",
       "LogisticRegression                 0.690209  0.692030  \n",
       "LogisticRegression_best_estimator  0.706260  0.705392  \n",
       "LinearSVC_best_estimator           0.704655  0.706799  \n",
       "LinearSVC                          0.709470  0.712074  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.sort_values(by=['f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x222317d7be0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log.sort_values(by=['f1_score']).plot(kind='barh',figsize=[7,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class FocalLoss(keras.losses.Loss):\n",
    "    def __init__(self, gamma=2., alpha=4.,\n",
    "                 reduction=keras.losses.Reduction.AUTO, name='focal_loss'):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        Notice: y_pred is probability after softmax\n",
    "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
    "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
    "        Focal Loss for Dense Object Detection\n",
    "        https://arxiv.org/abs/1708.02002\n",
    "\n",
    "        Keyword Arguments:\n",
    "            gamma {float} -- (default: {2.0})\n",
    "            alpha {float} -- (default: {4.0})\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__(reduction=reduction,\n",
    "                                        name=name)\n",
    "        self.gamma = float(gamma)\n",
    "        self.alpha = float(alpha)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
    "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
    "\n",
    "        Returns:\n",
    "            [tensor] -- loss.\n",
    "        \"\"\"\n",
    "        epsilon = 1.e-9\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(\n",
    "            tf.subtract(1., model_out), self.gamma))\n",
    "        fl = tf.multiply(self.alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return reduced_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn.datasets as skds\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "x = df_incidents_l3['token_desc']\n",
    "y = df_incidents_l3['Assignment_group']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.3, random_state=13,stratify=y)\n",
    "\n",
    "num_labels = 22\n",
    "vocab_size = 50000\n",
    "batch_size = 64\n",
    " \n",
    "# define Tokenizer with Vocab Size\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    " \n",
    "x_train = tokenizer.texts_to_matrix(X_train, mode='tfidf')\n",
    "x_test = tokenizer.texts_to_matrix(X_test, mode='tfidf')\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                2500050   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22)                682       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 22)                0         \n",
      "=================================================================\n",
      "Total params: 2,502,262\n",
      "Trainable params: 2,502,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1744 samples, validate on 436 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "2 root error(s) found.\n  (0) Internal:  Blas GEMM launch failed : a.shape=(64, 50000), b.shape=(50000, 50), m=64, n=50, k=50000\n\t [[node dense_1/MatMul (defined at C:\\Users\\divya\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\t [[loss/activation_3_loss/focal_loss/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_23/has_valid_nonscalar_shape/then/_159/has_invalid_dims/concat/_32]]\n  (1) Internal:  Blas GEMM launch failed : a.shape=(64, 50000), b.shape=(50000, 50), m=64, n=50, k=50000\n\t [[node dense_1/MatMul (defined at C:\\Users\\divya\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_1598]\n\nFunction call stack:\nkeras_scratch_graph -> keras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-c3e3f75d4444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                     verbose=1,validation_split=0.2,callbacks=[es_callback])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal:  Blas GEMM launch failed : a.shape=(64, 50000), b.shape=(50000, 50), m=64, n=50, k=50000\n\t [[node dense_1/MatMul (defined at C:\\Users\\divya\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n\t [[loss/activation_3_loss/focal_loss/weighted_loss/broadcast_weights/assert_broadcastable/is_valid_shape/else/_23/has_valid_nonscalar_shape/then/_159/has_invalid_dims/concat/_32]]\n  (1) Internal:  Blas GEMM launch failed : a.shape=(64, 50000), b.shape=(50000, 50), m=64, n=50, k=50000\n\t [[node dense_1/MatMul (defined at C:\\Users\\divya\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_1598]\n\nFunction call stack:\nkeras_scratch_graph -> keras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(30))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    " \n",
    "model.compile(loss=FocalLoss(alpha=1),\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,validation_split=0.2,callbacks=[es_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    " \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Save the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf_lr.best_estimator_, 'model_l3.pkl', compress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finals Conclusions fo Approach2\n",
    "\n",
    "- We first analysed the dataset provided to us, undestood the structure of the data provided - number of columns, field , datatypes etc.\n",
    "- We did Exploratory Data Analysis to derive further insights from this data set and we found that\n",
    "    - Data is very much imbalanced, there are around ~45% of the Groups with less than 20 tickets.\n",
    "    - Few of the tickets are in foreign language like German\n",
    "    - The data has lot of noise in it, for eg- few tickets related to account setup are spread across multiple assignment groups.\n",
    "    \n",
    "- We performed the data cleaning and preprocessing\n",
    "    - Translation: A small number of tickets were written in German. Hence, we used the Google translate python api  to convert German to English to generate the input data for the next steps. However, the google translator rest api can only process a limited number of texts on a daily basis, so we translated the text in batches and saved the file for further processing.\n",
    "    - Make text all lowercase so that the algorithm does not treat the same words in different cases as different\n",
    "    - Removing Noise i.e everything that isnt in a standard number or letter i.e Punctuation, Numerical values\n",
    "    - Removing extract spaces\n",
    "    - Removed punctuations\n",
    "    - Removed words containing numbers\n",
    "    - Stopword Removal: Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words\n",
    "    - Lemmatization\n",
    "    - Tokenization: Tokenization is just the term used to describe the process of converting the normal text strings into a list of tokens i.e words that we actually want. Sentence tokenizer can be used to find the list of sentences and Word tokenizer can be used to find the list of words in strings.\n",
    "    \n",
    "\n",
    "- We then ran a basic benchmarck model using the cleaned and preprocessed dataset\n",
    "    - Since the dataset is very imbalanced, We considered a subset of groups for predictions.  In 74 groups, 46% of tickets belong to group 1 and 16 groups just have more than 100 tickets, rest of the Assignment groups have very less ticket counts which might not add much value to the model prediction. If we conducted random sampling towards all the subcategories, then we would face a problem that we might miss all the tickets in some categories. Hence, we considered the groups that have more than 100 tickets. \n",
    "    - We trained the data using below models:\n",
    "        - Multinomial NB\n",
    "        - Linear Support vector Machine\n",
    "        - Logistic regression\n",
    "        - Xgboost\n",
    "        \n",
    "-  LinearSVC gives better performance with \n",
    "    accuracy 0.833642\n",
    "    f1 score 0.818053\n",
    "\n",
    "<b> Although, it seems like the call is biased towards GRP_0 which has a majority of samples. </b>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Even after downsampling the data we see that the predictions are biased towards GRP_0 which has a majority of samples.\n",
    "- Imbalance causes two problems:\n",
    "    - Training is inefficient as most samples are easy examples that contribute no useful learning signal;\n",
    "    - The easy examples can overwhelm training and lead to degenerate models.\n",
    "    A common solution is to perform some form of hard negative mining that samples hard examples during training or more complex sampling/re weighing schemes.In order to handle the imbalance problem  we used class_weight=balanced hyperparameter while training the model, which tells the model to \"pay more attention\" to samples from an under-represented class.  \n",
    "- Although, the accuracy and f1_score went down. This ensured that the classes were being correctly classified with lesser number of missclassification and good precision/recall scores for all the classes\n",
    "\n",
    "- Next, we used Approach 2 where the ticket would be classified into L1/L2 or L3 classes and then it would be further classified into one of the given assignment groups. \n",
    "\n",
    "- We first created a model to classify the given tickets as l1/l2 or l3 ticket, we found that Linear SVC was giving a better score.\n",
    "- Next, another model was trained considering only l1/l2 level of incidents consisting of GRP_0 and GRP_8.\n",
    "- Finally, a third model was trained considering l3 level of tickets.\n",
    "\n",
    "- We also used hyperparameter tuning, to identify the best classifier with best parameters. We found that LinearSVC was performing the best among all the other classifiers.\n",
    "- We also tried keras implementation with focal loss as a loss function to handle the class imbalance problem, which helps in giving more weightage to groups will less samples, but the results were not satifactory.\n",
    "  \n",
    " - Finally, Logistic Regression gave better performance with hyperparameter tuning and this model would be used for classifying the L3 tickets into one of the groups.\n",
    "    - accuracy 0.706260\n",
    "    - f1 score 0.705392\n",
    "\n",
    "\n",
    "The performance can be further improved by collecting more data for tickets and by running deep learning models like RNN and LSTM's."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
